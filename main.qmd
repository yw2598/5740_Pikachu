---
title: "Main"
format: html
editor: visual
---

```{r}
library(parsnip)
library(recipes)
library(dials)  # For tuning parameter objects
library(workflows)  # For creating workflows
library(rsample)  # For resampling if needed
library(yardstick)  # For model metrics
library(xgboost)
library(parsnip)
library(rsample)

wine_data <- read.csv("wine-quality-white-and-red.csv")
# Assuming the column that indicates the wine type is named 'type'

red_wine <- wine_data[wine_data$type == "red", ] |>
  select(-type)
white_wine <- wine_data[wine_data$type == "white", ] |>
  select(-type)

normalize_min_max <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}
# Excluding the first and the last column
red_feature_columns <- names(red_wine)[2:(ncol(red_wine) - 1)]

white_feature_columns <-  names(white_wine)[2:(ncol(white_wine) - 1)]

# Apply Min-Max Scaling
# Apply min-max scaling to red wine features
red_wine[red_feature_columns] <- lapply(red_wine[red_feature_columns], normalize_min_max)

# Apply min-max scaling to white wine features
white_wine[white_feature_columns] <- lapply(white_wine[white_feature_columns], normalize_min_max)

```

```{r}
# Load necessary libraries
library(caret)     # For machine learning algorithms
library(randomForest)  # For Random Forest algorithm
library(e1071)         # For SVM and Naive Bayes
library(kknn)          # For k-Nearest Neighbors
library(rpart)         # For decision trees
library(nnet)          # For multilayer perceptron

# Split data into training and testing sets
set.seed(123)
training_index <- createDataPartition(white_wine$quality, p=0.75, list= FALSE)
training_data_w <- white_wine[training_index, ]
testing_data_w <- white_wine[-training_index, ]

training_index <- createDataPartition(red_wine$quality, p=0.75, list= FALSE)
training_data_r <- red_wine[training_index, ]
testing_data_r <- red_wine[-training_index, ]

```

```{r fig.width= 6, fig.height= 6}
set.seed(123)
# Training a Decision Tree model
model_dt_w <- rpart(quality ~ ., data = training_data_w, method = "class")
# Plot the tree
plot(model_dt_w)
text(model_dt_w)
# Making predictions on the test data
predictions_dt_w <- predict(model_dt_w, testing_data_w, type = "class")
# Actual labels from the test data
actual_labels_dt_w <- testing_data_w$quality

# Calculate accuracy
accuracy_dt_w <- mean(predictions_dt_w == actual_labels_dt_w)

# Print the accuracy
print(paste("Decision Tree Model Accuracy:", accuracy_dt_w))

```
```{r fig.width= 6, fig.height= 6}
set.seed(123)
# Training a Decision Tree model
model_dt_r <- rpart(quality ~ ., data = training_data_r, method = "class")
# Plot the tree
plot(model_dt_r)
text(model_dt_r)
# Making predictions on the test data
predictions_dt_r <- predict(model_dt_r, testing_data_r, type = "class")
# Actual labels from the test data
actual_labels_dt_r <- testing_data_r$quality

# Calculate accuracy
accuracy_dt_r <- mean(predictions_dt_r == actual_labels_dt_r)

# Print the accuracy
print(paste("Decision Tree Model Accuracy:", accuracy_dt_r))
```




```{r}
set.seed(123)

training_data_w$quality <- as.factor(training_data_w$quality)
testing_data_w$quality <- as.factor(testing_data_w$quality)

# Training a Random Forest model
model_rf_w <- randomForest(quality ~ ., data = training_data_w, ntree = 20)

# Viewing the importance of variables
importance(model_rf_w)
varImpPlot(model_rf_w)

# Making predictions on the test data
predictions_rf_w <- predict(model_rf_w, testing_data_w)

# Actual labels from the test data
actual_labels_rf_w <- testing_data_w$quality

# Calculate accuracy
accuracy_rf_w <- mean(predictions_rf_w == actual_labels_rf_w)

# Print the accuracy
print(paste("Random Forest Model Accuracy:", accuracy_rf_w))

```
```{r}

set.seed(123)

training_data_r$quality <- as.factor(training_data_r$quality)
testing_data_r$quality <- as.factor(testing_data_r$quality)

# Training a Random Forest model
model_rf_r <- randomForest(quality ~ ., data = training_data_r, ntree = 20)

# Viewing the importance of variables
importance(model_rf_r)
varImpPlot(model_rf_r)

# Making predictions on the test data
predictions_rf_r <- predict(model_rf_r, testing_data_r)

# Actual labels from the test data
actual_labels_rf_r <- testing_data_r$quality

# Calculate accuracy
accuracy_rf_r <- mean(predictions_rf_r == actual_labels_rf_r)

# Print the accuracy
print(paste("Random Forest Model Accuracy:", accuracy_rf_r))

```



```{r}
set.seed(123)
# Training a Naive Bayes model
model_nb_w <- naiveBayes(quality ~ ., data = training_data_w)

model_nb_w
# Predictions
predictions_nb_w <- predict(model_nb_w, testing_data_w)


# Calculating the accuracy
actual_labels_w <- testing_data_w$quality
accuracy_nb_w <- mean(predictions_nb_w == actual_labels_w)

# Printing the accuracy
print(paste("Naive Bayes Model Accuracy:", accuracy_nb_w))

```


```{r}
set.seed(123)
# Training a Naive Bayes model
model_nb_r <- naiveBayes(quality ~ ., data = training_data_r)

model_nb_r
# Predictions
predictions_nb_r <- predict(model_nb_r, testing_data_r)


# Calculating the accuracy
actual_labels_r <- testing_data_r$quality
accuracy_nb_r <- mean(predictions_nb_r == actual_labels_r)

# Printing the accuracy
print(paste("Naive Bayes Model Accuracy:", accuracy_nb_r))

```



```{r}



set.seed(123)

training_data_w$quality <- as.factor(training_data_w$quality)
testing_data_w$quality <- as.factor(testing_data_w$quality)

# Fit multinomial logistic regression
multinom_model_w <- multinom(quality ~ ., data = training_data_w)

# Predict and calculate accuracy
predictions_multinom_w <- predict(multinom_model_w, testing_data_w)
accuracy_multinom_w <- mean(predictions_multinom_w == testing_data_w$quality)
print(paste("Multinomial Logistic Regression Model Accuracy:", accuracy_multinom_w))

```
```{r}
set.seed(123)

training_data_r$quality <- as.factor(training_data_r$quality)
testing_data_r$quality <- as.factor(testing_data_r$quality)

# Fit multinomial logistic regression
multinom_model_r <- multinom(quality ~ ., data = training_data_r)

# Predict and calculate accuracy
predictions_multinom_r <- predict(multinom_model_r, testing_data_r)
accuracy_multinom_r <- mean(predictions_multinom_r == testing_data_r$quality)
print(paste("Multinomial Logistic Regression Model Accuracy:", accuracy_multinom_r))

```

```{r}

set.seed(123)

recipe_w <- recipe(quality ~ ., data = training_data_w) %>%
  step_normalize(all_predictors())

# Define the model with explicit settings
xgb_spec_w <- boost_tree(
  trees = 200,                # Number of trees
  tree_depth = 17,             # Maximum depth of each tree
  min_n = 5,                 # Minimum number of observations in nodes
  loss_reduction = 1.0,       # Minimum loss reduction required for a further partition
  sample_size = 0.75,         # Subsample ratio of the training instance
  mtry = 5,                   # Number of variables randomly sampled as candidates at each split
  learn_rate = 0.05           # Learning rate (shrinkage)
) %>%
  set_mode("classification") %>%
  set_engine("xgboost")

# Create the workflow
xgb_workflow_w <- workflow() %>%
  add_model(xgb_spec_w) %>%
  add_recipe(recipe_w)

# Fit the model
xgb_fit_w <- fit(xgb_workflow_w, data = training_data_w)

# Assuming xgb_fit is the fitted model workflow from previous steps

class_predictions_w <- predict(xgb_fit_w, new_data = testing_data_w, type = "class")

# Bind the predictions with the true outcomes
results_w <- bind_cols(testing_data_w, predictions = class_predictions_w$.pred_class)

# Calculate accuracy
model_accuracy_w <- accuracy(results_w, truth = quality, estimate = predictions)

# Print the accuracy
print(model_accuracy_w)

```


```{r}
# Load the data
wine_data_2 <- read.csv("wine-quality-white-and-red.csv")

wine_red <- wine_data_2[wine_data$type == "red",]

wine_red <- wine_red |>
  select(-type)
# Set the seed for reproducibility
set.seed(123)

# Split the data into training and testing sets with a 75:25 ratio
data_split <- initial_split(wine_red, prop = 0.75)

# Extract the training and testing data
train_data <- training(data_split)
test_data <- testing(data_split)


train_data$quality <- as.factor(train_data$quality)
test_data$quality <- as.factor(test_data$quality)

# Setup the recipe

recipe <- recipe(quality ~ ., data = train_data) %>%
  step_normalize(all_predictors())

# Define the model with explicit settings
xgb_spec <- boost_tree(
  trees = 100,                # Number of trees
  tree_depth = 16,             # Maximum depth of each tree
  min_n = 10,                 # Minimum number of observations in nodes
  loss_reduction = 1.0,       # Minimum loss reduction required for a further partition
  sample_size = 0.75,         # Subsample ratio of the training instance
  mtry = 3,                   # Number of variables randomly sampled as candidates at each split
  learn_rate = 0.06           # Learning rate (shrinkage)
) %>%
  set_mode("classification") %>%
  set_engine("xgboost")

# Create the workflow
xgb_workflow <- workflow() %>%
  add_model(xgb_spec) %>%
  add_recipe(recipe)

# Fit the model
xgb_fit <- fit(xgb_workflow, data = train_data)

# Assuming xgb_fit is the fitted model workflow from previous steps

class_predictions <- predict(xgb_fit, new_data = test_data, type = "class")

# Bind the predictions with the true outcomes
results <- bind_cols(test_data, predictions = class_predictions$.pred_class)

# Calculate accuracy
model_accuracy <- accuracy(results, truth = quality, estimate = predictions)

# Print the accuracy
print(model_accuracy)




```
